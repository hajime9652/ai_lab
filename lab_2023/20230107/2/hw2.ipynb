{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習1\n",
    "\n",
    "以下の処理を実装してください\n",
    "\n",
    "- センチメント分析(\"daigo/bert-base-japanese-sentiment\")\n",
    "- 穴埋め(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
    "- 要約(\"tsmatz/mt5_summarize_japanese\")\n",
    "- テキスト生成(\"rinna/japanese-gpt2-medium\")\n",
    "\n",
    "[Hubで日本語モデルを検索](https://huggingface.co/models?search=japanese)すると、各モデルの詳細が記載されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# センチメント分析(\"daigo/bert-base-japanese-sentiment\")\n",
    "def analyzer(input):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "input = \"私は幸福です。\"\n",
    "analyzer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 穴埋め(\"cl-tohoku/bert-base-japanese-whole-word-masking\")\n",
    "def unmasker(input):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "input = \"東北大学で[MASK]の研究をしています。\"\n",
    "unmasker(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要約(\"tsmatz/mt5_summarize_japanese\")\n",
    "def summarizer(input, max_length=100, min_length=30):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "input = \"人間の知的能力をコンピュータ上で実現する、様々な技術・ソフトウェア・コンピュータシステム。\\\n",
    "    応用例としては、自然言語処理（機械翻訳・かな漢字変換・構文解析・文章要約等）、専門家の推論・判断を模倣するエキスパートシステム、画像データを解析し特定のパターンを検出・抽出する画像認識等がある。\\\n",
    "    1956年にダートマス会議でジョン・マッカーシーにより命名された。\\\n",
    "    現在では、記号処理を用いた知能の記述を主体とする情報処理や研究でのアプローチという意味あいでも使われている。\\\n",
    "    家庭用電気機械器具の制御システムやゲームソフトの思考ルーチンもこう呼ばれることもある。\\\n",
    "    プログラミング言語 LISP による「ELIZA」というカウンセラーを模倣したプログラム（人工無脳）がしばしば引き合いに出されるが、\\\n",
    "    計算機に人間の専門家の役割をさせようという「エキスパートシステム」と呼ばれる研究・情報処理システムの実現は、人間が暗黙に持つ常識の記述が問題となり、当時のその技術では実用化は困難と考えられていた。\\\n",
    "    人工的な知能の実現へのアプローチとしては、「ファジィ理論」や「ニューラルネットワーク」などのようなアプローチも知られているが、従来の人工知能であるGOFAI（Good Old Fashioned AI）との差は記述の記号的明示性にある。\\\n",
    "    その後「サポートベクターマシン」が注目を集めた。また、自らの経験を元に学習を行う強化学習という手法もある。\\\n",
    "    「この宇宙において、知性とは最も強力な形質である（レイ・カーツワイル）」という言葉通り、知性を機械的に表現し実装するということは極めて重要な作業である。\\\n",
    "    画像処理におけるディープラーニングの有用性が競技会で世界的に認知された2012年頃から急速に研究が活発となり、第3次人工知能ブームが到来。2016年から2017年にかけて、\\\n",
    "    ディープラーニングを導入したAIが完全情報ゲームである囲碁などのトップ棋士、さらに不完全情報ゲームであるポーカーの世界トップクラスのプレイヤーも破り、\\\n",
    "    麻雀では「Microsoft Suphx（Super Phoenix）」がオンライン対戦サイト「天鳳」でAIとして初めて十段に到達するなど最先端技術として注目されている。\\\n",
    "    第3次人工知能ブームの主な革命は、自然言語処理、センサーによる画像処理など視覚的側面が特に顕著であるが、社会学、倫理学、技術開発、経済学などの分野にも大きな影響を及ぼしている。\"\n",
    "\n",
    "summarizer(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
    "\n",
    "# テキスト生成(\"rinna/japanese-gpt2-medium\")\n",
    "def generator(input, max_length=100, num_return_sequences=3):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "input = \"生命、宇宙、そして万物についての究極の疑問の答えは、\"\n",
    "generator(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 演習2\n",
    "\n",
    "Handling multiple sequences\n",
    "- “I’ve been waiting for a HuggingFace course my whole life.” と “I hate this so much!”に手動でトークン化を適用してください。\n",
    "- これらをモデルに通して、セクション2と同じロジットが得られることを確認してください。(tensor([[-1.5607,  1.6123],[ 4.1692, -3.3464]], grad_fn=<AddmmBackward>))\n",
    "- 次に、パディングトークンを使ってそれらをバッチ処理し、適切なアテンションマスクを作成します。モデルを通したときに、同じ結果が得られるかどうかチェックしてください(waiting for と hateを含むそれぞれの文が適切に分類されていますか？)\n",
    "\n",
    "\n",
    "MRPC\n",
    "- 訓練集合の要素15と検証集合の要素87を確認してください。それらのラベルは何ですか？\n",
    "- トレーニングセットの要素15を取り出し、2つの文章を別々に、そしてペアとしてトークン化します。2つの結果の違いは何ですか？\n",
    "\n",
    "GLUE SST-2\n",
    "- MRPCと同等な前処理をGLUE SST-2データセットで再現してください。ペアではなく単文で構成されているので少し違いますが、それ以外の部分は同じように見えるはずです。\n",
    "- モデルのファインチューニングを行なってください。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eaac4ee8e735b6cee17c1b0358cfc8773b6176eb143c6cf3f1e52e7612ffbee2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
