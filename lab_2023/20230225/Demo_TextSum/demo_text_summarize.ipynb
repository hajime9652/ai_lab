{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 要約\n",
    "要約には２種類の方法があります。\n",
    "- 抽出型要約\n",
    "- 抽象型要約（生成型要約とも）\n",
    "\n",
    "歴史的には、抽出型要約から抽象型要約が発展した流れがあります。  \n",
    "seq2seqから始まって、BERTの登場、そしてT5/BARTへと発展していきます。  \n",
    "上記、それぞれのモデルで要約に特化したモデルが公開されています。例えばBERTSUMなどです。  \n",
    "BARTから派生したものとして、PEGASUSなどがあります。  \n",
    "BARTはTransformerのエンコーダ・デコーダモデルです。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 要約のタスク\n",
    "- 抽出型要約：情報抽出のタスク\n",
    "- 抽象型要約：テキスト生成のタスク\n",
    "\n",
    "要約のタスクには、次に挙げるような分類も存在します。\n",
    "- 複数文書の要約 (Multi-Document Summarization)\n",
    "- クエリフォーカス要約 (Query Focused Summarization)\n",
    "- ヘッドライン生成 (Headline Generation)\n",
    "- キーフレーズ抽出 (Keyphrase Extraction)\n",
    "\n",
    "実務として要約を扱う場合のほとんどが、上記のような条件付きの要約になります。  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 要約の精度を測る\n",
    "抽象型要約は、テキスト生成のタスクでした。  \n",
    "前回の講義で扱ったように、テキスト生成を行う場合のデコード方法には複数あります。  \n",
    "その中で、生成されたテキストの人間らしさのようなことも扱いました（ビームサーチとサンプリング）。  \n",
    "要約においても同様ですが、さらに情報抽出という観点を加えて、精度を測る必要があります。\n",
    "\n",
    "#### 精度指標\n",
    "要約の指標と言えば、まずはこの２つです。\n",
    "- ROUGE：カバー率の評価\n",
    "- BLEU：一致率の評価\n",
    "\n",
    "ROUGEは、人間が作成した要約における単語（や単語の組み合わせ）が、生成された要約でどれだけ出現するかを計算します。  \n",
    "この指標は、生成された要約が長ければ良いスコアを出します。\n",
    "\n",
    "BLEUは、ROUGEと逆に、生成された要約における単語（や単語の組み合わせ）が、人間の作成した要約でどれだけ出現するかを計算します。  \n",
    "この指標は、生成された要約が短ければ良いスコアを出します。\n",
    "\n",
    "実際には、要約の指標としてはROUGEが使われます。  \n",
    "要約においては長さの制限があることがほとんどで、良いスコアを出すために長いテキストを生成することがそもそも出来ないためです。  \n",
    "BLEUは要約で使われない訳ではありませんが、指標としては翻訳タスクのメジャーな指標です。\n",
    "\n",
    "#### 意味を考慮した精度指標\n",
    "\n",
    "上記の2つは2000年代前半に提案された指標ですが、2020年に提案された方法が意味を考慮した指標として最近注目されています。  \n",
    "**「要約から質問文を生成し、入力文書・質問文の対が出す答えと、要約・質問文の対が出す答えの間の一致度を測る」**  \n",
    "この指標をQAGS（Question Answering and Generation for Summarization）と呼びます。読み方は\"kags\"です。  \n",
    "\n",
    "\n",
    "![image.png](https://storage.googleapis.com/zenn-user-upload/ea13d322fbd2-20220531.png)\n",
    "\n",
    "評価の流れは、次の３ステップから成ります。\n",
    "\n",
    "1. 要約から質問文を生成\n",
    "2. 入力文書・質問文、要約文書・質問文の組み合わせで、それぞれの質問応答\n",
    "3. 回答内容の一致度の評価\n",
    "\n",
    "ROUGEなどとは全く別物の複雑な方法になっています。  \n",
    "ROUGEなどよりも人間の評価との相関があるという実験結果が着目されています。  \n",
    "\n",
    "#### モデルを使って、モデルを評価する\n",
    "QASGでは、質問文の生成・回答の生成で二つのテキスト生成のモデルが必要になります。  \n",
    "モデルを評価するのに、その他のモデルを使う指標は、比較的新しい考え方です。  \n",
    "基本的には人間との評価と相関がある指標が採用されていきますが、それに沿った指標を作ることができています。  \n",
    "要約に限らず、他のモデルを活用して、特定のモデルの挙動を確かめる傾向があるので、ここで流れを確認しておきましょう。  \n",
    "\n",
    "今回は、次のモデルを使います。\n",
    "- 評価対象の要約モデル：tsmatz/mt5_summarize_japanese\n",
    "- 質問文の生成：sonoisa/t5-base-japanese-question-generation\n",
    "- 回答の生成：tsmatz/roberta_qa_japanese\n",
    "\n",
    "現時点では、質問文の生成を行う日本語モデルは、正解を与える必要がありました。  \n",
    "今回は、要約する文書と合わせて正解の設定を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers sentencepiece gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer, AutoModelForSeq2SeqLM, RobertaForQuestionAnswering\n",
    "\n",
    "# 評価対象の要約モデル\n",
    "tokenizer_sum = AutoTokenizer.from_pretrained(\"tsmatz/mt5_summarize_japanese\")\n",
    "model_sum = AutoModelForSeq2SeqLM.from_pretrained(\"tsmatz/mt5_summarize_japanese\")\n",
    "\n",
    "# 質問文の生成\n",
    "tokenizer_gen_q = T5Tokenizer.from_pretrained(\"sonoisa/t5-base-japanese-question-generation\")\n",
    "model_gen_q = T5ForConditionalGeneration.from_pretrained(\"sonoisa/t5-base-japanese-question-generation\")\n",
    "\n",
    "# 回答の生成\n",
    "tokenizer_qa = AutoTokenizer.from_pretrained(\"tsmatz/roberta_qa_japanese\")\n",
    "model_qa = RobertaForQuestionAnswering.from_pretrained(\"tsmatz/roberta_qa_japanese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要約対象のテキスト１\n",
    "# https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%B3%E3%83%91%E3%83%B3%E3%83%9E%E3%83%B3\n",
    "ARTICLE = \"\"\"\n",
    "ポケットモンスターの原点は、1996年2月27日に発売されたゲームボーイ用ソフト『ポケットモンスター 赤・緑』である。\n",
    "開発元はゲームフリーク。コンセプトメーカーにしてディレクターを務めたのは、同社代表取締役でもある田尻智。\n",
    "この作品が小学生を中心に、口コミから火が点き大ヒットとなり、以降も多くの続編が発売されている（詳しくは「ポケットモンスター（ゲーム）」を参照）。\n",
    "ゲーム本編作品だけでなく、派生作品や関連作品が数多く発売されている（詳しくはポケットモンスターの関連ゲームを参照）。\n",
    "\n",
    "ポケモンはゲームのみならず、アニメ化、キャラクター商品化、カードゲーム、アーケードゲームと様々なメディアミックス展開がなされ、日本国外でも人気を獲得している。\n",
    "\n",
    "ポケモン関連ゲームソフトの累計出荷数は、全世界で2017年11月時点で3億本以上[1]、2022年3月時点で4億4000万本以上に達している[2]。\n",
    "その中で、メインシリーズの累計販売本数は2016年2月時点での最新作、ニンテンドー3DS『オメガルビー・アルファサファイア』までの25作品で2億100万本となる[3]。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要約の実行\n",
    "inputs = tokenizer_sum(\"summarize: \" + ARTICLE, return_tensors=\"pt\")\n",
    "outputs = model_sum.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=300,  # 生成数の上限\n",
    "    min_length=150,  # 生成数の下限\n",
    "    num_beams=5  # ビームサーチの設定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ゲーム本編「ポケットモンスター 赤・緑」の累計販売本数が、全世界で3億万本以上に達し、世界各地で人気を獲得している。ゲームボーイ用ソフトは、2017年2月27日に発売されたゲームソフトで2億4000万本の売り上げが、過去最多を記録した。このほか、人気が点き大ヒットとなり、世界的に人気を集めているゲームフリークのディレクターを務めた田尻智英氏が、同社の創業者だった。 ポケモン関連ソフトが「ポケモン」と名付けられた。これにより、作品や関連作品が世界中で話題を集めた、ゲームの本編作品と関連作が次々と発表された。さらに、新作シリーズが話題となっている 。\n"
     ]
    }
   ],
   "source": [
    "# 精度を評価するモデルの要約結果\n",
    "ARTICLE_SUM = tokenizer_sum.decode(outputs[0], skip_special_tokens=True)\n",
    "print(ARTICLE_SUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問を生成するモデルに与える必要がある正解単語の設定\n",
    "# 要約結果から選ぶ\n",
    "ANSWER = [\"2月27日\", \"ポケットモンスター 赤・緑\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問文の生成\n",
    "answer_context_list = [(answer, ARTICLE_SUM) for answer in ANSWER]  # 解答を質問生成する元となる文（要約結果）とセットにする。\n",
    "\n",
    "generated_questions = []\n",
    "\n",
    "for answer, context in answer_context_list:\n",
    "  # モデルに入力可能な形式に変換する\n",
    "  # 「answer: 」と「context: 」を使った形式に変換にする\n",
    "  input = tokenizer_gen_q(f\"answer: {answer} context: {context}\", return_tensors=\"pt\")\n",
    "\n",
    "  # 質問文を生成する\n",
    "  output = model_gen_q.generate(\n",
    "    input['input_ids'],\n",
    "    max_new_tokens=100,\n",
    "    num_beams=4  # ビームサーチの設定\n",
    "  )\n",
    "\n",
    "  # 生成された問題文のトークン列を文字列に変換する。\n",
    "  output = tokenizer_gen_q.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "  generated_questions.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ゲームボーイ用ソフトの「赤・緑」はいつ発売されましたか?', '全世界で3億本以上売れたゲームはどれですか?']\n"
     ]
    }
   ],
   "source": [
    "print(generated_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "質問: ゲームボーイ用ソフトの「赤・緑」はいつ発売されましたか?\n",
      "記事からの回答: 、1996年2月27日に発売された\n",
      "要約からの回答: 、2017年2月27日に発売された\n",
      "質問: 全世界で3億本以上売れたゲームはどれですか?\n",
      "記事からの回答: ポケモン関連ゲームソフト\n",
      "要約からの回答: 「ポケットモンスター 赤・緑」\n"
     ]
    }
   ],
   "source": [
    "def extract_answer(question, text):\n",
    "    \"\"\"質問応答\n",
    "\n",
    "    Args\n",
    "        question: str\n",
    "            質問文のテキスト\n",
    "        text: str\n",
    "            質問に回答するために参照するテキスト\n",
    "    \n",
    "    Returns\n",
    "        answer: str\n",
    "            回答のテキスト\n",
    "    \"\"\"\n",
    "    inputs = tokenizer_qa(question, text, return_tensors=\"pt\")  # tokenizerには複数のテキストを与える\n",
    "    \n",
    "    # 正解箇所の予測\n",
    "    outputs = model_qa(**inputs)\n",
    "    answer_start_scores = outputs.start_logits\n",
    "    answer_end_scores = outputs.end_logits\n",
    "\n",
    "    # 予測結果の開始と終了のインデックスを取得\n",
    "    answer_start = torch.argmax(answer_start_scores)\n",
    "    answer_end = torch.argmax(answer_end_scores) + 1\n",
    "    \n",
    "    # tokenizerの結果から正解を抽出する\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    \n",
    "    answer = tokenizer_qa.decode(input_ids[answer_start:answer_end])\n",
    "    # FYI: 上記の処理は、下記の処理と同じ結果になる（他では下を使っていることもある）\n",
    "    # ids->token->string\n",
    "    # answer = tokenizer_qa.convert_tokens_to_string(\n",
    "    #     tokenizer_qa.convert_ids_to_tokens(input_ids[answer_start:answer_end])\n",
    "    # )\n",
    "\n",
    "    return answer\n",
    "\n",
    "\n",
    "for q in generated_questions:\n",
    "    answer_article = extract_answer(q, ARTICLE)\n",
    "    answer_sum = extract_answer(q, ARTICLE_SUM)\n",
    "\n",
    "    print(f\"質問: {q}\")\n",
    "    print(f\"記事からの回答: {answer_article}\")\n",
    "    print(f\"要約からの回答: {answer_sum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 人力の評価\n",
    "上記の結果は評価するにも質問の数が足りませんが、これを人力でやることも多々あります。  \n",
    "評価者に質問を与え、モデルの要約結果を見ながら答えてもらう方法です。  \n",
    "QAGSを人手でやるようなもので、丁寧に評価することが可能です。  \n",
    "この方法では評価者は単純び質問に答えるだけなので、評価方法の習得などは必要がありません。  \n",
    "\n",
    "\n",
    "一方で、評価を専門的に行う立場の人（テスター）は、次の観点での5段階評価などを行います。\n",
    "- 可読性 (Readability) \n",
    "- 流暢さ (Fluency) \n",
    "- 情報量の多さ (Informative) \n",
    "- 内容の一貫性 (Consistency)\n",
    "\n",
    "\n",
    "#### こういうレベルからスタートする\n",
    "開発の現場では、「ちょっとさ、要約のモデル作ってみてくれない」と軽いノリで案件が生まれたりします。  \n",
    "そんな時は、「動かしてみました」と軽いノリで返したりします。  \n",
    "その内容からもう少しやってみようなどの話し合いがあったりします。  \n",
    "\n",
    "上記の例は個人的な経験ですが、実際にNLPのモデルを使って何かをやってみようというと、既存で使えるモデルを動かしてみることがから始めます。  \n",
    "そこで**まず行うのがモデルの評価**で、まぁこんなもんかとか、ここ弱いなとかを確認します。  \n",
    "\n",
    "ここから、ファインチューニングのためのデータの予算がついたり、アノテーター（学習データを作る人）・テスター（モデルを評価する人）のリソースが確保できたりします。  \n",
    "どこまでを実証実験・PoCと呼ぶかは会社次第ですが、ベンチャーですとデモを作って投資家にプレゼンするというのが日常的な流れでした。\n",
    "ベンチャーでなくともプロジェクトとして予算がついていれば、同じようなデモを行います。 \n",
    "\n",
    "ChatGPTなどのインパクトは今年くらいは持つと思います。  \n",
    "ぜひ、経営者の目線がAIに向いているタイミングで、デモ開発の予算つけてもらって動いてみたりしてください。  \n",
    "自社でユニークなデータを持っている場合は、大学などとの共同研究も企画しやすいです。  \n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考文献：\n",
    "- 要約のサーベイまとめ記事：https://qiita.com/siida36/items/4c0dbaa07c456a9fadd0\n",
    "- QAGSの提案論文：https://aclanthology.org/2020.acl-main.450/\n",
    "- ROUGEの解説記事（日本語）：https://qiita.com/icoxfog417/items/65faecbbe27d3c53d212\n",
    "- QAGSの解説記事（日本語）：https://zenn.dev/ty_nlp/articles/aaad1aec70d53e"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習\n",
    "\n",
    "#### その１:動作確認\n",
    "次の要約対象のテキストを使って、質問生成・質問応答の流れを実行してみましょう。\n",
    "- 下記のアンパンマンについてのテキストを要約してください。\n",
    "- 要約結果から正解を二つ選択して、質問生成用のモデルに与えるためのANSWERを定義してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 要約対象のテキスト２\n",
    "# https://www.asahi.com/articles/ASR2F328DR2DULEI001.html?iref=com_rnavi_arank_nr01\n",
    "ARTICLE = \"\"\"\n",
    "アンパンマンの生みの親であるやなせたかしの作品で1968年に「バラの花とジョー」、\n",
    "「チリンの鈴」の絵本や映画にいち早くアンパンマンが登場しているが、この時はまだ人間の姿。\n",
    "この童話は一年間連載された。[5]アンパンマン、やなせたかしの作品としての、「アンパンマン」は、\n",
    "PHP研究所が発行する青年向け雑誌『PHP』の通巻第257号に当たる、『こどものえほん』の1969年10月号[6]（同年10月1日刊行）に掲載された青年向け読物、\n",
    "やなせたかし（絵と文）「アンパンマン」という形が初出である[7][8][9]。\n",
    "この時期、やなせが『こどものえほん』のために執筆した読物は連載12本の短編で、「アンパンマン」はその6本目の作品であった。\n",
    "これら12篇は、株式会社山梨シルクセンター（※3年後、株式会社サンリオへ社名変更）より単行本『十二の真珠』名義で1970年に刊行された。\n",
    "\n",
    "空腹に喘ぐ人の所へ駆け付けて、自らの大事な持ち物であるパンを差し出して食べるよう勧めるという、のちのアンパンマンに通じる物語の骨組みが、\n",
    "この作品のおいて早くも整えられている[10][6]。\n",
    "絵本・漫画・アニメなど、のちに描かれるアンパンマンとの大きな違いと言えば、第一に主人公のアンパンマンが普通の人間のおじさんであり[10][6]、\n",
    "パンは所有物に過ぎなかったことである。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 質問を生成するモデルに与える必要がある正解単語の設定\n",
    "# 要約結果から選ぶ\n",
    "ANSWER = [\"\", \"\"]  # ここを変更してください。このままでも動きます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "アンパンマンの生みの親である、やなせたかしの作品として、1970年に出版された青年向け絵本や小説、漫画、アニメ、映画、ドラマなど、さまざまな作品が掲載された。この絵本は、作者のパンを描いた作者が、その名義で名付けられた。この作品の短編で、読者に衝撃を与えた――。 英医学誌「ネイチャー」に掲載された 作品 が5日、出版され、この著称で明らかになった。出版した 出版本 では、 絵本・漫画・アニメ やアニメなど 、絵本の読み物 と絵本、コミック、児童書、小説の作者、英作家、ジョン・ホプキンス大学の集計 で発表した。\n",
      "\n",
      "\n",
      "質問: やなせたかしの本にはどんな種類の本がありますか?\n",
      "記事からの回答: 12本の短編で、「アンパンマン」はその6本目の作品であった。 これら12篇は、株式会社山梨シルクセンター(※3年後、株式会社サンリオへ社名変更)より単行本『十二の真珠』\n",
      "要約からの回答: 短編\n",
      "\n",
      "\n",
      "質問: やなせたかしの本にはどんな種類の本がありますか?\n",
      "記事からの回答: 12本の短編で、「アンパンマン」はその6本目の作品であった。 これら12篇は、株式会社山梨シルクセンター(※3年後、株式会社サンリオへ社名変更)より単行本『十二の真珠』\n",
      "要約からの回答: 短編\n"
     ]
    }
   ],
   "source": [
    "# 要約の実行\n",
    "inputs = tokenizer_sum(\"summarize: \" + ARTICLE, return_tensors=\"pt\")\n",
    "outputs = model_sum.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=300,  # 生成数の上限\n",
    "    min_length=150,  # 生成数の下限\n",
    "    num_beams=5  # ビームサーチの設定\n",
    ")\n",
    "\n",
    "# 精度を評価するモデルの要約結果\n",
    "ARTICLE_SUM = tokenizer_sum.decode(outputs[0], skip_special_tokens=True)\n",
    "print(ARTICLE_SUM)\n",
    "\n",
    "# 質問文の生成\n",
    "answer_context_list = [(answer, ARTICLE_SUM) for answer in ANSWER]  # 解答を質問生成する元となる文（要約結果）とセットにする。\n",
    "\n",
    "generated_questions = []\n",
    "\n",
    "for answer, context in answer_context_list:\n",
    "  # モデルに入力可能な形式に変換する\n",
    "  # 「answer: 」と「context: 」を使った形式に変換にする\n",
    "  input = tokenizer_gen_q(f\"answer: {answer} context: {context}\", return_tensors=\"pt\")\n",
    "\n",
    "  # 質問文を生成する\n",
    "  output = model_gen_q.generate(\n",
    "    input['input_ids'],\n",
    "    max_new_tokens=100,\n",
    "    num_beams=4  # ビームサーチの設定\n",
    "  )\n",
    "\n",
    "  # 生成された問題文のトークン列を文字列に変換する。\n",
    "  output = tokenizer_gen_q.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "  generated_questions.append(output)\n",
    "\n",
    "# 回答生成\n",
    "for q in generated_questions:\n",
    "  answer_article = extract_answer(q, ARTICLE)\n",
    "  answer_sum = extract_answer(q, ARTICLE_SUM)\n",
    "\n",
    "  print(f\"\\n\")\n",
    "  print(f\"質問: {q}\")\n",
    "  print(f\"記事からの回答: {answer_article}\")\n",
    "  print(f\"要約からの回答: {answer_sum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### その２：デモ実装\n",
    "質問生成・質問応答の流れを実行できるUIをGradioで実装してみましょう。\n",
    "\n",
    "##### 具体的な作業内容\n",
    "- イベント用の関数の実装\n",
    "    - 要約生成の関数作成\n",
    "    - 質問生成の関数作成\n",
    "    - 回答生成の関数作成\n",
    "- `gr.Blocks()`を使ったUIの実装\n",
    "    - 要約生成のUI作成\n",
    "    - 質問生成のUI作成\n",
    "    - 回答生成のUI作成\n",
    "- イベントの実装（btn.clickなど）\n",
    "    - 要約生成の実行ボタン作成\n",
    "    - 質問生成の実行ボタン作成\n",
    "    - 回答生成の実行ボタン作成\n",
    "\n",
    "\n",
    "##### 条件\n",
    "- 要約対象のテキストを入力できる\n",
    "- 要約を実行し、要約結果を確認できる\n",
    "- 要約結果を見て、質問生成のための2つの正解を入力できる\n",
    "- 質問生成のための正解から、質問文を生成できる\n",
    "- 質問文を確認できる\n",
    "- 要約前のテキストと要約後のテキストを条件として与えて、質問文への回答を実行できる\n",
    "- それぞれの結果を確認できる\n",
    "\n",
    "##### 補足\n",
    "- 要約生成の関数とUIはシンプル\n",
    "    - ユーザーからのテキストを１つ受け取り、要約結果を返す\n",
    "- 質問生成の関数とUIもシンプル\n",
    "    - ユーザーからテキストを2つ受け取り、それぞれの結果（質問文）を返す\n",
    "- 回答生成の関数とUIはすこし注意が必要\n",
    "    - ユーザーからの入力はない\n",
    "    - 2つの質問文と2つのテキスト（回答のために参照する要約前と要約後のテキスト）の組み合わせ\n",
    "    - 回答生成を４回実行することになる。\n",
    "    - 1つのボタンで実行できるようにするためには、回答生成の関数をまとめて処理する関数が必要\n",
    "\n",
    "##### 参考UI\n",
    "![layout](https://s3.gifyu.com/images/teset.png)\n",
    "\n",
    "#### その３:テスター作業\n",
    "上記で実装したUIのexamplesを作ってみましょう。\n",
    "\n",
    "まず次の２点を行なってください。\n",
    "- 要約対象のテキストを探してきて、実際に要約を試してみてください\n",
    "- 正解の選定、質問文の選定、回答の生成までの確認を行なってください\n",
    "\n",
    "ユーザーが入力が必要なのは、要約対象のテキストと２つの正解です。  \n",
    "これをexamplesとして表示させて、examplesのデータをクリックすると入力されるようにしてください\n",
    "\n",
    "##### ![eg](https://s3.gifyu.com/images/-2023-02-15-4.24.22.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer, AutoTokenizer, AutoModelForSeq2SeqLM, RobertaForQuestionAnswering\n",
    "\n",
    "# 0.モデルのロード, Examplesの準備\n",
    "# TODO 評価対象の要約モデルをロード\n",
    "\n",
    "\n",
    "# TODO 質問文の生成モデルをロード\n",
    "\n",
    "\n",
    "# TODO 回答の生成モデルをロード\n",
    "\n",
    "# Example 1\n",
    "eg_text_1 = \"\"\"\n",
    "ポケットモンスターの原点は、1996年2月27日に発売されたゲームボーイ用ソフト『ポケットモンスター 赤・緑』である。\n",
    "開発元はゲームフリーク。コンセプトメーカーにしてディレクターを務めたのは、同社代表取締役でもある田尻智。\n",
    "この作品が小学生を中心に、口コミから火が点き大ヒットとなり、以降も多くの続編が発売されている（詳しくは「ポケットモンスター（ゲーム）」を参照）。\n",
    "ゲーム本編作品だけでなく、派生作品や関連作品が数多く発売されている（詳しくはポケットモンスターの関連ゲームを参照）。\n",
    "\n",
    "ポケモンはゲームのみならず、アニメ化、キャラクター商品化、カードゲーム、アーケードゲームと様々なメディアミックス展開がなされ、日本国外でも人気を獲得している。\n",
    "\n",
    "ポケモン関連ゲームソフトの累計出荷数は、全世界で2017年11月時点で3億本以上[1]、2022年3月時点で4億4000万本以上に達している[2]。\n",
    "その中で、メインシリーズの累計販売本数は2016年2月時点での最新作、ニンテンドー3DS『オメガルビー・アルファサファイア』までの25作品で2億100万本となる[3]。\n",
    "\"\"\"\n",
    "eg_ans_1_1 = \"2月27日\"\n",
    "eg_ans_1_2 = \"ポケットモンスター 赤・緑\"\n",
    "\n",
    "# Example 2\n",
    "eg_text_2 = \"\"\"\n",
    "アンパンマンの生みの親であるやなせたかしの作品で1968年に「バラの花とジョー」、\n",
    "「チリンの鈴」の絵本や映画にいち早くアンパンマンが登場しているが、この時はまだ人間の姿。\n",
    "この童話は一年間連載された。[5]アンパンマン、やなせたかしの作品としての、「アンパンマン」は、\n",
    "PHP研究所が発行する青年向け雑誌『PHP』の通巻第257号に当たる、『こどものえほん』の1969年10月号[6]（同年10月1日刊行）に掲載された青年向け読物、\n",
    "やなせたかし（絵と文）「アンパンマン」という形が初出である[7][8][9]。\n",
    "この時期、やなせが『こどものえほん』のために執筆した読物は連載12本の短編で、「アンパンマン」はその6本目の作品であった。\n",
    "これら12篇は、株式会社山梨シルクセンター（※3年後、株式会社サンリオへ社名変更）より単行本『十二の真珠』名義で1970年に刊行された。\n",
    "\n",
    "空腹に喘ぐ人の所へ駆け付けて、自らの大事な持ち物であるパンを差し出して食べるよう勧めるという、のちのアンパンマンに通じる物語の骨組みが、\n",
    "この作品のおいて早くも整えられている[10][6]。\n",
    "絵本・漫画・アニメなど、のちに描かれるアンパンマンとの大きな違いと言えば、第一に主人公のアンパンマンが普通の人間のおじさんであり[10][6]、\n",
    "パンは所有物に過ぎなかったことである。\n",
    "\"\"\"\n",
    "eg_ans_2_1 = \"アンパンマン\"\n",
    "eg_ans_2_2 = \"やなせたかし\"\n",
    "\n",
    "# 1. イベント用の関数\n",
    "def summy(text):\n",
    "    \"\"\"要約\n",
    "\n",
    "    Args\n",
    "        text: str\n",
    "            要約対象のテキスト\n",
    "\n",
    "    Returns\n",
    "        summarize_text: str\n",
    "            要約結果のテキスト\n",
    "\n",
    "    TODO\n",
    "        処理の実装\n",
    "    \"\"\"\n",
    "    summarize_text = ...\n",
    "    \n",
    "    return summarize_text\n",
    "\n",
    "def generate_questions(answer_1, answer_2, text):\n",
    "    \"\"\"質問生成\n",
    "\n",
    "    Args\n",
    "        answers: list[str]\n",
    "            質問生成のための正解単語のリスト\n",
    "        text: str\n",
    "            質問文を生成する際に参照するテキスト\n",
    "        \n",
    "    Returns\n",
    "        generated_questions: list[str]\n",
    "            生成された質問文のリスト\n",
    "\n",
    "    TODO\n",
    "        処理の実装\n",
    "    \"\"\"\n",
    "    generated_questions = ...\n",
    "\n",
    "    return generated_questions\n",
    "\n",
    "def extract_answer(question, text):\n",
    "    \"\"\"質問応答\n",
    "\n",
    "    Args\n",
    "        question: str\n",
    "            質問文のテキスト\n",
    "        text: str\n",
    "            質問に回答するために参照するテキスト\n",
    "    \n",
    "    Returns\n",
    "        answer: str\n",
    "            回答のテキスト\n",
    "\n",
    "    TODO\n",
    "        処理の実装\n",
    "    \"\"\"\n",
    "    answer = ...\n",
    "\n",
    "    return answer\n",
    "\n",
    "def extract_answer_all(gen_q_1, gen_q_2, source_text, sum_text):\n",
    "    \"\"\"extract_answer()をまとめて実行する\n",
    "    TODO\n",
    "        処理の実装\n",
    "    \"\"\"\n",
    "    a_source_1 = ...\n",
    "    a_sum_1 = ...\n",
    "    a_source_2 = ...\n",
    "    a_sum_2 = ...\n",
    "\n",
    "    return a_source_1, a_sum_1, a_source_2, a_sum_2\n",
    "\n",
    "# 2. UIの定義\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"### 1. 要約生成\")\n",
    "    # TODO 要約のための入出力UIの作成\n",
    "    btn_summy = gr.Button(\"要約生成\")\n",
    "    \n",
    "    gr.Markdown(\"### 2. 質問生成\")\n",
    "    # TODO 質問文生成のための入力UIの作成\n",
    "\n",
    "    btn_generate_questions = gr.Button(\"質問生成\")\n",
    "\n",
    "    gr.Markdown(\"### 3. 回答生成\")\n",
    "    # TODO 質問文を表示するUIの作成\n",
    "    btn_extract_answer = gr.Button(\"回答生成\")\n",
    "    # TODO それぞれの回答を表示するUIの作成\n",
    "    \n",
    "    # 2. イベント発火\n",
    "    btn_summy.click(\n",
    "        summy,\n",
    "        inputs=...,  # TODO 定義したUIのコンポーネントを与える\n",
    "        outputs=...  # TODO 定義したUIのコンポーネントを与える\n",
    "    )\n",
    "    btn_generate_questions.click(\n",
    "        generate_questions,\n",
    "        inputs=...,  # TODO 定義したUIのコンポーネントを与える\n",
    "        outputs=...  # TODO 定義したUIのコンポーネントを与える\n",
    "    )\n",
    "    btn_extract_answer.click(extract_answer_all,\n",
    "        inputs=...,  # TODO 定義したUIのコンポーネントを与える\n",
    "        outputs=...  # TODO 定義したUIのコンポーネントを与える\n",
    "    )\n",
    "\n",
    "    # Examplesの定義\n",
    "    gr.Markdown(\"## Examples\")\n",
    "    gr.Examples()  # TODO Exampleにデータを与えて、表示させる\n",
    "\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82e52f2285c871893785b6211b1b0fb91a1e90d57630bc3da094798a3ae6fb15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
