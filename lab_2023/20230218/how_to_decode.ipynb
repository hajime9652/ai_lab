{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp3XPuaTu9jl"
      },
      "source": [
        "\n",
        "# How to generate text:デコード方法の違いを利用したテキスト生成"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KxLvv6UaPa33"
      },
      "source": [
        "### はじめに\n",
        "\n",
        "改良されたトランスフォーマアーキテクチャと大規模な教師なし学習データの他に、**より良いデコーディング方法**も重要な役割を果たしています。\n",
        "\n",
        "さまざまなデコーディング戦略の概要を簡単に説明し、`transformers` ライブラリを使って、わずかな労力でそれらを実装する方法を紹介します。\n",
        "\n",
        "以下の機能はすべて 自己回帰モデルのテキスト生成に使用することができます。自己回帰モデルでは、単語列の確率分布が次の単語の条件付き分布の積に分解できるという仮定に基づいています。\n",
        "\n",
        "$$ P(w_{1:T} | W_0 ) = \\prod_{t=1}^T P(w_{t} | w_{1: t-1}, W_0) \\text{ ,with }  w_{1: 0} = \\emptyset, $$\n",
        "\n",
        "$W_0$ は初期の *文脈* の単語列です。単語列の長さ $T$ は通常 *on-the-fly* で決定され、タイムステップ $t=T$ に対応します。\n",
        "\n",
        "ここでは、主に *Greedy search*, *Beam search*, *Top-K sampling*, *Top-p sampling* を中心に、有名なデコード方法を紹介します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si4GyYhOQMzi"
      },
      "source": [
        "準備\n",
        "1.  ライブラリのインストール\n",
        "2.  モデルのロード\n",
        "\n",
        "今回は、rinna/japanese-gpt2-smallを使用します。\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbzZ_IVTtoQe",
        "outputId": "7a6316f4-4fd1-419f-8ba5-ecee8f2bf59a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.0 tokenizers-0.13.2 transformers-4.26.0\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ue2kOQhXTAMU"
      },
      "outputs": [],
      "source": [
        "from transformers import T5Tokenizer, AutoModelForCausalLM, GenerationConfig\n",
        "\n",
        "# 0. モデルとトークナイザーの定義\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-gpt2-small\")\n",
        "tokenizer.do_lower_case = True  # rinna/japanese-gpt2特有のハック\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"rinna/japanese-gpt2-small\",\n",
        "    pad_token_id=tokenizer.eos_token_id  # warningを避けるために、padにEOSトークンを割りあてる\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Y7cgu9ohXP"
      },
      "source": [
        "### **Greedy Search**\n",
        "Greedy Searchでは、単に次の単語として最も確率の高い単語を選択するだけです：$w_t = argmax_{w}P(w | w_{1:t-1})$ を各タイムステップ $t$. 次のスケッチは、Greedy Searchを示しています。\n",
        "\n",
        "![Greedy Search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/greedy_search.png)\n",
        "\n",
        "単語 $\\text{\"The\"}$から始めると アルゴリズムは \n",
        "貪欲(Greedy)に確率の高い次の単語を選んでいくので、最終的に生成される単語列は、$\\text{\"The\", \"nice\", \"woman\"}$で、全体の確率は$0.5 \\times 0.4 = 0.2$となります。\n",
        "\n",
        "日本語で試してみましょう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWLd_J6lXz_t",
        "outputId": "5f77ea4b-9b36-49cc-d37d-2d4c2b15b2f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            " 福岡の観光スポットとして、まずは博多駅が挙げられます。\n",
            "博多駅には、博多駅ビルや博多駅ビルの2つの商業施設があります。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            " 博多駅ビルは、博多駅ビルの2階にある商業施設です。\n",
            "博多駅ビルは、博多駅ビルの2階にある商業施設です\n"
          ]
        }
      ],
      "source": [
        "text = \"福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。どんな観光体験が福岡に必要でしょうか\"\n",
        "\n",
        "inputs = tokenizer(text, add_special_tokens=False, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        ")\n",
        "outputs = model.generate(inputs, generation_config=config)\n",
        "generated = tokenizer.decode(outputs[0])\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BBn1ePmJvhrl"
      },
      "source": [
        "文脈に沿って生成する方法は合理的ですが、モデルはすぐに繰り返しを始めてしまいます。これは一般的なテキスト生成において非常に一般的な問題であり、Greedy SearchやBeam Searchにおいては特に強いようです。\n",
        "\n",
        "しかし、Greedy Searchの主な欠点は、上のスケッチで見られるように、低確率の単語の背後に隠された高確率の単語を見逃してしまうことです。\n",
        "\n",
        "条件付き確率の高い$0.9$の単語$\\text{\"has\"}$は、2番目に高い条件付き確率しかない単語$\\text{\"dog\"}$の後ろに隠れています。\n",
        "\n",
        "Beam Searchを使えば、この問題を軽減することができます。\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g8DnXZ1WiuNd"
      },
      "source": [
        "### **Beam search**\n",
        "Beam Searchでは、各ステップで最も可能性の高い仮説の `num_beams` を保持し、最終的に全体的に最も高い確率を持つ仮説を選択することで、隠れた高確率の単語列を見落とすリスクを減らすことができます。ここでは、`num_beams=2`を用いて説明します。\n",
        "\n",
        "![Beam search](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/beam_search.png)\n",
        "\n",
        "\n",
        "ステップ$1$では、最も可能性の高い仮説$\\text{\"The\", \"woman\"}$の他に、2番目に可能性の高い仮説$\\text{\"The\", \"dog\"}$も追跡しています。ステップ$2$では、$\\text{\"The\", \"dog\", \"has\"}$の確率は、$0.2$の$\\text{\"The\", \"nice\", \"woman\"}$よりも$0.36$高いことがわかりました。この簡単な例で最も可能性の高い単語列を見つけました。\n",
        "\n",
        "Beam Searchは、Greedy Searchよりも高い確率で常に出力を見つけますが、最も可能性の高い出力を見つけることは保証されていません。\n",
        "\n",
        "それでは、`transformers`でBeam Searchをどのように使うことができるか見てみよう。ここでは、`num_beams > 1` と `early_stopping=True` を設定し、すべてのビーム仮説がEOSトークンに到達した時点で生成が終了するようにしています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1R5kx30Ynej",
        "outputId": "2708c796-ff8a-4b8e-9b3c-22647d9f94ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            " 福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力\n"
          ]
        }
      ],
      "source": [
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    num_beams=5,  # Beam Searchの有効化\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "beam_output = model.generate(inputs, generation_config=config)\n",
        "\n",
        "generated = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "AZ6xs-KLi9jT"
      },
      "source": [
        "若干まともになっているようですが、出力には同じ単語列の繰り返しが含まれています。 \n",
        "簡単な解決策は、*n-grams* (*a.k.a.* $n$単語の単語列)ペナルティを導入することです。最も一般的な*n-grams*ペナルティは、すでに見た*n-gram*を作る可能性のある次の単語の確率を手動で$0$に設定することで、*n-gram*が2回出現しないようにします。\n",
        "\n",
        "それでは、`no_repeat_ngram_size=2`を設定して、*2-gram*が繰り返し出現しないようにしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy3iVJgfnkMi",
        "outputId": "c52d60ed-84c3-4846-a3bb-8f4de23d6a01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか? 今回は、福岡でおすすめの観光スポットをご紹介していきます。\n",
            " 博多駅や天神駅から徒歩5分ほどの場所にある「博多ラーメン」。\n",
            "博多のラーメンといえば、博多豚骨醤油ラーメンが有名ですよね。\n",
            "そんな博多で人気のお店をピックアップしてみましたので、ぜひ参考にしてみてくださいね! こちらの店は博多駅から歩いて5分の場所にあり、アクセスも抜群です。\n",
            "店内はカウンター席とテーブル席があり、おひとり様でも気軽に入れるのも嬉しいポイントですね♪ 店内に入ると、まず目に飛び込んでくるのがラーメンの看板。\n",
            "ラーメン好きにはたまらないお店だと思います。\n",
            " お店に入るとまず目に入るのはラーメンとつけ麺がセットになったお得なセットメニュー。\n",
            "お一人様はもちろん、家族連れやカップルでのお食事にもぴったりです! お店の雰囲気はとてもアットホームな感じでした。\n",
            "店員さんも気さくな方ばかりなので、初めての方でも安心してお食事を楽しめますよ。\n",
            " また、こちらのお店の名物は「つけめん」!お客さんの好みに合わせて麺を選べるのはもちろんのこと、スープの濃さや麺の太さ\n"
          ]
        }
      ],
      "source": [
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    num_beams=5,  # Beam Searchの有効化\n",
        "    early_stopping=True,\n",
        "    no_repeat_ngram_size=2,  # 繰り返し出現しないようにオプションを追加\n",
        ")\n",
        "beam_output = model.generate(inputs, generation_config=config)\n",
        "\n",
        "generated = tokenizer.decode(beam_output[0], skip_special_tokens=True)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nxsksOGDpmA0"
      },
      "source": [
        "だいぶ良くなりました。繰り返しが出てこなくなったのがわかります。\n",
        "\n",
        "Beam Searchのもう一つの重要な特徴は、生成後にトップのビームを比較して、目的に合ったビームを選択できることです。\n",
        "\n",
        "`num_return_sequences` というパラメータにビームを何本返すかを設定します。ただし、`num_return_sequences <= num_beams` となるよう\n",
        "にしてください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ClO3VphqGp6",
        "outputId": "0590e12f-cedc-40f2-f7ac-fa3e27751bac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "0番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか? 今回は、福岡でおすすめの観光スポットをご紹介していきます。\n",
            " 博多駅や天神駅から徒歩5分ほどの場所にある「博多ラーメン」。\n",
            "博多のラーメンといえば、博多豚骨醤油ラーメンが有名ですよね。\n",
            "そんな博多で人気のお店をピックアップしてみましたので、ぜひ参考にしてみてくださいね! こちらの店は博多駅から歩いて5分の場所にあり、アクセスも抜群です。\n",
            "店内はカウンター席とテーブル席があり、おひとり様でも気軽に入れるのも嬉しいポイントですね♪ 店内に入ると、まず目に飛び込んでくるのがラーメンの看板。\n",
            "ラーメン好きにはたまらないお店だと思います。\n",
            " お店に入るとまず目に入るのはラーメンとつけ麺がセットになったお得なセットメニュー。\n",
            "お一人様はもちろん、家族連れやカップルでのお食事にもぴったりです! お店の雰囲気はとてもアットホームな感じでした。\n",
            "店員さんも気さくな方ばかりなので、初めての方でも安心してお食事を楽しめますよ。\n",
            " また、こちらのお店の名物は「つけめん」!お客さんの好みに合わせて麺を選べるのはもちろんのこと、スープの濃さや麺の太さ\n",
            "\n",
            "1番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか? 今回は、福岡でおすすめの観光スポットをご紹介していきます。\n",
            " 博多駅や天神駅から徒歩5分ほどの場所にある「博多ラーメン」。\n",
            "博多のラーメンといえば、博多豚骨醤油ラーメンが有名ですよね。\n",
            "そんな博多で人気のお店をピックアップしてみましたので、ぜひ参考にしてみてくださいね! こちらの店は博多駅から歩いて5分の場所にあり、アクセスも抜群です。\n",
            "店内はカウンター席とテーブル席があり、おひとり様でも気軽に入れるのも嬉しいポイントですね♪ 店内に入ると、まず目に飛び込んでくるのがラーメンの看板。\n",
            "ラーメン好きにはたまらないお店だと思います。\n",
            " お店に入るとまず目に入るのはラーメンとつけ麺がセットになったお得なセットメニュー。\n",
            "お一人様はもちろん、家族連れやカップルでのお食事にもぴったりです! お店の雰囲気はとてもアットホームな感じでした。\n",
            "店員さんも気さくな方ばかりなので、初めての方でも安心してお食事を楽しめますよ。\n",
            " また、こちらのお店の名物は「つけめん」!お客さんの好みに合わせて麺を選べるのはもちろんのこと、スープの濃さや麺の太さ\n",
            "\n",
            "2番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか? 今回は、福岡でおすすめの観光スポットをご紹介していきます。\n",
            " 博多駅や天神駅から徒歩5分ほどの場所にある「博多ラーメン」。\n",
            "博多のラーメンといえば、博多豚骨醤油ラーメンが有名ですよね。\n",
            "そんな博多で人気のお店をピックアップしてみましたので、ぜひ参考にしてみてくださいね! こちらの店は博多駅から歩いて5分の場所にあり、アクセスも抜群です。\n",
            "店内はカウンター席とテーブル席があり、おひとり様でも気軽に入れるのも嬉しいポイントですね♪ 店内に入ると、まず目に飛び込んでくるのがラーメンの看板。\n",
            "ラーメン好きにはたまらないお店だと思います。\n",
            " お店に入るとまず目に入るのはラーメンとつけ麺がセットになったお得なセットメニュー。\n",
            "お一人様はもちろん、家族連れやカップルでのお食事にもぴったりです! お店の雰囲気はとてもアットホームな感じでした。\n",
            "店員さんも気さくな方ばかりなので、初めての方でも安心してお食事を楽しめますよ。\n",
            " また、こちらのお店の名物は「つけめん」!お客さんの好みに合わせて麺を選べるのはもちろんのこと、スープの濃さや麺の太さ\n",
            "\n",
            "3番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか? 今回は、福岡でおすすめの観光スポットをご紹介していきます。\n",
            " 博多駅や天神駅から徒歩5分ほどの場所にある「博多ラーメン」。\n",
            "博多のラーメンといえば、博多豚骨醤油ラーメンが有名ですよね。\n",
            "そんな博多で人気のお店をピックアップしてみましたので、ぜひ参考にしてみてくださいね! こちらの店は博多駅から歩いて5分の場所にあり、アクセスも抜群です。\n",
            "店内はカウンター席とテーブル席があり、おひとり様でも気軽に入れるのも嬉しいポイントですね♪ 店内に入ると、まず目に飛び込んでくるのがラーメンの看板。\n",
            "ラーメン好きにはたまらないお店だと思います。\n",
            " お店に入るとまず目に入るのはラーメンとつけ麺がセットになったお得なセットメニュー。\n",
            "お一人様はもちろん、家族連れやカップルでのお食事にもぴったりです! お店の雰囲気はとてもアットホームな感じでした。\n",
            "店員さんも気さくな方ばかりなので、初めての方でも安心してお食事を楽しめますよ。\n",
            " また、こちらのお店の名物は「つけめん」!お客さんの好みに合わせて麺を選べるのはもちろんのこと、スープの濃さや麺の太さ\n",
            "\n",
            "4番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか? 今回は、福岡でおすすめの観光スポットをご紹介していきます。\n",
            " 博多駅や天神駅から徒歩5分ほどの場所にある「博多ラーメン」。\n",
            "博多のラーメンといえば、博多豚骨醤油ラーメンが有名ですよね。\n",
            "そんな博多で人気のお店をピックアップしてみましたので、ぜひ参考にしてみてくださいね! こちらの店は博多駅から歩いて5分の場所にあり、アクセスも抜群です。\n",
            "店内はカウンター席とテーブル席があり、おひとり様でも気軽に入れるのも嬉しいポイントですね♪ 店内に入ると、まず目に飛び込んでくるのがラーメンの看板。\n",
            "ラーメン好きにはたまらないお店だと思います。\n",
            " お店に入るとまず目に入るのはラーメンとつけ麺がセットになったお得なセットメニュー。\n",
            "お一人様はもちろん、家族連れやカップルでのお食事にもぴったりです! お店の雰囲気はとてもアットホームな感じでした。\n",
            "店員さんも気さくな方ばかりなので、初めての方でも安心してお食事を楽しめますよ。\n",
            " また、こちらのお店の名物は「つけめん」!お客さんの好みに合わせて麺を選べるのはもちろんのこと、スープの濃さや麺の太さ\n"
          ]
        }
      ],
      "source": [
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    num_beams=5,  # Beam Searchの有効化\n",
        "    early_stopping=True,\n",
        "    no_repeat_ngram_size=2,  # 繰り返し出現しないようにオプションを追加\n",
        "    num_return_sequences=5,  # 返すセンテンスの数\n",
        ")\n",
        "\n",
        "# beam_output => beam_outputsとなっています。\n",
        "beam_outputs = model.generate(inputs, generation_config=config)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  generated = tokenizer.decode(beam_outputs[0], skip_special_tokens=True)\n",
        "\n",
        "  print(f\"\\n{i}番の生成結果\")\n",
        "  # 見やすさのために、改行コードを挿入\n",
        "  print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HhLKyfdbsjXc"
      },
      "source": [
        "見ての通り、5つのBeam Searchのデコード結果は互いにわずかに異なるだけです。\n",
        "\n",
        "Beam Searcが最良の選択肢ではない理由がいくつか提唱されています。\n",
        "\n",
        "- Beam Searcは、機械翻訳や要約のように、目的とする生成の長さがある程度予測可能なタスクでは非常にうまく機能します。しかし、これは、対話やストーリーの生成など、想定する出力長が大きく変化する可能性がある場合はそうではありません。\n",
        "\n",
        "- Beam Searcが繰り返し生成に大きく苦しむことを見てきました。これは、テキスト生成における*n-gram*やその他のペナルティで制御することが特に困難です。なぜなら、強制的に「繰り返しなし」にすることと、同一の*n-gram*の繰り返しサイクルとの間の良いトレードオフを見つけることは、多くの微調整を必要とするからです。\n",
        "\n",
        "- [Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751)で論じられているように、高品質の人間のテキストは、高確率に従わない。言い換えれば、人間は、生成されたテキストには驚きを与えているし、つまらない/予測可能なものをわざわざ書かないということです。著者らは、モデルが人間のテキストに与えるであろう確率と、ビームサーチが行うこととの比較をプロットすることで、このことをうまく示しています。\n",
        "\n",
        "![alt text](https://blog.fastforwardlabs.com/images/2019/05/Screen_Shot_2019_05_08_at_3_06_36_PM-1557342561886.png)\n",
        "\n",
        "\n",
        "人間は0から文を考えることができます。ここで、ランダム性を導入してみましょう。"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XbbIyK84wHq6"
      },
      "source": [
        "### **Sampling**\n",
        "\n",
        "その最も基本的な形式であるサンプリングは、その条件付き確率分布に従って、次の単語 $w_t$ をランダムに選ぶことを意味します。\n",
        "\n",
        "$w_t \\sim P(w|w_{1:t-1})$.\n",
        "\n",
        "上記を例に、サンプリング時のテキスト生成を可視化したものが以下の図です。\n",
        "\n",
        "\n",
        "![vanilla_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/sampling_search.png)\n",
        "\n",
        "サンプリングを使ったテキスト生成は、もはや*deterministic*ではないことが明らかになる。単語$\\text{\"car\"}$は 条件付き確率 $P(w | \\text{\"The\"})$からサンプリングされます。続いて $\\text{\"drives\"}$は $P(w | \\text{\"The\"}, \\text{\"car\"})$からサンプリングされます。\n",
        "\n",
        "`transformers`では、`do_sample=True`とし、`top_k=0` で*Top-K*のサンプリングを無効にします(これについては後述)。以下では、説明のために `random_seed=0` を固定します。random_seedは自由に変更してください。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRAz4D-Ks0_4",
        "outputId": "62e36689-58ae-424f-c8aa-d26fcf762691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            "街の歴史を感じることが出来るのではありませんか。\n",
            "福岡の落ち着いた雰囲気でお団子に生まれ変わらせてくれるお店を紹介してまいります。\n",
            "ちなみに司馬遼太郎の故郷である福岡を総なめするため、この場所にお団子が作られたのです。\n",
            "博多にあるお団子店はその多くが江戸時代に「高橋(斉彬)」が作成したお菓子の味が本場中国製法なので『アジアの道玄坂』と呼ばれているそうです。\n",
            "近年では大阪など大都市だけではなく日常の様子も再現するお洒落な店舗も入店しているそうです。\n",
            "別途事前に調べる必要がありますが、詳しく教えてくれるお店もあり詳しく地域ごとに紹介してくださいました。\n",
            "相談にのってくれるお店もありますので初めてお団子の通販でお団子を購入予定の方はオーダーしてからのお団子の購入をしたいなら、こちらのページを参考にしてくださいね。\n",
            " 福岡発祥のお団子屋さんを紹介しているウェブサイトです。\n",
            "カテゴリーにお店のなかったお店を紹介していただき、そのページがあります。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import set_seed\n",
        "\n",
        "# 結果の再現性担保のための設定。値を変えてみると、結果が変わります。\n",
        "set_seed(21)\n",
        "\n",
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    do_sample=True,  # サンプリングを有効化\n",
        "    top_k=0   #（k=0の場合は、Top-Kサンプリングが無効）\n",
        ")\n",
        "\n",
        "sample_output = model.generate(inputs, generation_config=config)\n",
        "\n",
        "generated = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mQHuo911wfT-"
      },
      "source": [
        "面白いですね。テキストは大丈夫そうですが、よく見るとあまりまとまりがありません。3-grams *お団子に生まれ* と *店舗も入店* は非常に奇妙で、人間が書いたようにはみえません。これが単語列をサンプリングするときの大きな問題です。モデルはしばしば支離滅裂な失言を生成します。\n",
        "\n",
        "トリックは、[softmax](https://en.wikipedia.org/wiki/Softmax_function#Smooth_arg_max)の`temperature`を下げることで、分布 $P(w|w_{1:t-1})$ をシャープにすることです(高確率の単語のより確率を上げ、低確率の単語の確率を下げる)。\n",
        "\n",
        "上の例で`temperature`を適用した例は以下のようになります。\n",
        "\n",
        "![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/sampling_search_with_temp.png?raw=true)\n",
        "\n",
        "ステップ $t=1$ の次の単語の条件付き分布はかなりシャープになり、 $\\text{\"car\"}$ が選択される可能性はほとんどなくなります。\n",
        "\n",
        "\n",
        "`temperature=0.7` を設定して、分布をシャープにさせる方法を見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgJredc-0j0Z",
        "outputId": "5c6aa188-6fc3-44e5-cdc1-00c1021bfaf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            " 観光スポットとしては、福岡の商業施設やデパート、官公庁などが有名です。\n",
            "博多駅周辺は、博多駅や天神駅へも、飛行機を降りて徒歩5分以内で行くことができます。\n",
            "観光スポットとしてはあまり有名なスポットではないのですが、博多駅周辺は一日で回れる距離で、ホテルや旅館が立ち並ぶエリアです。\n",
            "飲食店も多く、夜遅くまで営業しているので、夜遅くまで営業しているお店は便利です。\n",
            " 観光客には、博多駅周辺や天神駅周辺で有名な飲食店が好まれます。\n",
            "飲食店では、別途に様々なメニューがあり、お土産選びの参考になります。\n",
            " 地域ごとに特色のある飲食店も多いのですが、特に有名なお店は、博多駅周辺や天神駅周辺に立地しています。\n",
            "有名なお店は、福岡で有名なラーメン屋や焼き鳥屋、居酒屋などです。\n",
            " 福岡のグルメスポットとして、観光客には、博多駅周辺が特に人気です。\n",
            "観光客にお土産選びの参考になれば嬉しいですね。\n",
            " レジャー施設やスポーツ施設、観光地もたくさんあるので、福岡に観光に行くなら、観光スポットを観光しに行きましょう。\n",
            " 博多駅周辺は、観光地として有名なので、有名な飲食店がたくさんあります。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 結果の再現性担保のための設定。値を変えてみると、結果が変わります。\n",
        "set_seed(21)\n",
        "\n",
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    do_sample=True,  # サンプリングを有効化\n",
        "    top_k=0,   #（k=0の場合は、Top-Kサンプリングが無効）\n",
        "    temperature=0.7  # 低確率の候補に対する感度を下げる\n",
        ")\n",
        "\n",
        "sample_output = model.generate(inputs, generation_config=config)\n",
        "\n",
        "generated = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kzGuu24hZZnq"
      },
      "source": [
        "話題も変わってしまいましたが、よくなったように見えます。変なn-gramが少なくなって、出力がもう少しまとまりが出てきました。`temperature`を適用することで分布のランダム性を低くすることができますが、その限界では、`temperature` $ \\to 0$ を設定すると、`temperature`スケーリングされたサンプリングはGreedy Searchと同じになり、以前と同じ問題に悩まされることになります。\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "binNTroyzQBu"
      },
      "source": [
        "### **Top-K Sampling**\n",
        "**Top-K**サンプリングと呼ばれる単純だが非常に強力なサンプリングスキームがあります。*Top-K* サンプリングでは、最も可能性の高い*K*次の単語をフィルタリングし、それらの*K*次の単語のみに確率を再分配します。\n",
        "GPT2では、このサンプリング方式を採用しており、これがテキスト生成に成功した理由の一つと言われています。\n",
        "\n",
        "上の例の両方のサンプリングステップで使用される単語の範囲を3単語から10単語に拡張して、*Top-K*サンプリングをより良く説明しています。\n",
        "\n",
        "![top_k_sampling](https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/top_k_sampling.png)\n",
        "\n",
        "$k = 6$としたので、両方のサンプリングステップでは、サンプリングプールを6単語に制限します。$V_{\\text{top-K}}$と定義された6つの最も可能性の高い単語は、最初のステップでは全体の確率の3分の2しか含まれていませんが、2つ目のステップではほぼすべての確率を含んでいます。それにも関わらず、変な候補 $\\text{\"not\", \"the\", \"small\", \"telled\"}$ を除去することに成功していることがわかります。\n",
        "\n",
        "\n",
        "`top_k=50`を設定して、*Top-K*がどのように使えるか見てみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBtDOdD0wx3l",
        "outputId": "5d4fc735-2c38-405b-f178-e803baa1e14e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            "これから、楽しみにしていきたいと思います。\n",
            " 観光で訪れたことがない人も意外なほど、多くの魅力があります。\n",
            "福岡を訪れたときは、観光で訪れたときに地元の方に話しかけられたり、話相手になっていただければ嬉しいですね。\n",
            " 街は博多を代表して、福岡市を中心とした市街地に多く存在していますが、特に観光では、福岡市を中心とした博多を中心に、福岡市を中心とした中心市街地に点在しています。\n",
            " 観光で訪れる際には、多くの方にその魅力を知ってもらえると嬉しいですね。\n",
            " 街の中にはカフェやレストラン、宿泊施設などがあり、ゆっくりと過ごしているだけで雰囲気が伝わってきますが、福岡には「ランチスポット」がいくつもあり、グルメとショッピングを楽しむための拠点にもなります。\n",
            " グルメやショッピングに便利な飲食店は、福岡だけではなく日本各地にあるため、特に観光の際には観光を充実させたいところになります。\n",
            "福岡では、福岡のグルメに関するお店を簡単に選ぶことができますし、グルメに関しても福岡のグルメに詳しい人におすすめのお店を簡単に選ぶことができます。\n",
            " グルメを楽しみたい人はたくさんいますし、お店はたくさんありますが、その中でもおすすめのスポットを見ていきましょう。\n",
            " 福岡にあるお店を幾つか紹介していきますので、参考にしてみてください。\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 結果の再現性担保のための設定。値を変えてみると、結果が変わります。\n",
        "set_seed(4)\n",
        "\n",
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    do_sample=True,  # サンプリングを有効化\n",
        "    top_k=50,  # 確率の高い上位k個に制限する（k=0の場合は、Top-Kサンプリングが無効）\n",
        ")\n",
        "sample_output = model.generate(inputs, generation_config=config)\n",
        "\n",
        "generated = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y77H5m4ZmhEX"
      },
      "source": [
        "全然悪くないですよね!? このテキストは、間違いなく、これまでのところ最も*人間らしい* テキストです。\n",
        "*Top-K*サンプリングで懸念されることは、次の単語の確率分布 $P(w|w_{1:t-1})$からフィルタリングされる単語の数を動的に適応させないことです。\n",
        "これは問題となります。ある単語は非常に鋭い分布（上のグラフの右側の分布）からサンプリングされ、他の単語はより平坦な分布（上のグラフの左側の分布）からサンプリングされるかもしれないからです。\n",
        "\n",
        "ステップ $t=1$ では、*Top-K* は、次のような可能性を排除します。\n",
        "サンプル $\\text{\"people\", \"big\", \"house\", \"cat\"}$ が妥当な候補と思われます。一方で、ステップ$t=2$では、この方法では、$\\text{\"down\", \"a\"}$のような、かなり合わない単語が単語のサンプルプールに含まれています。このように、サンプルプールを固定サイズ*K*に制限することは、鋭い分布のためにモデルが失言を生成する危険にさらし、平坦な分布のためにモデルの創造性を制限する可能性があります。\n",
        "この直感は、[Ari Holtzman et al. (2019)](https://arxiv.org/abs/1904.09751)が**Top-p**\b-または**nucleus** - samplingを作成することにつながりました。\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ki9LAaexzV3H"
      },
      "source": [
        "### **Top-p (nucleus) sampling**\n",
        "\n",
        "*Top-p*サンプリングでは、最も可能性の高い*K*語のみからサンプリングするのではなく、累積確率が確率*p*を超える可能性のある最小の単語集合から選択します。確率は、この単語集合の中で再分配されます。このようにして、単語集合のサイズ（*a.k.a.* 集合内の単語数）は、次の単語の確率分布に応じて動的に増減することができます。\n",
        "\n",
        "\n",
        "![top_p_sampling](https://github.com/patrickvonplaten/scientific_images/blob/master/top_p_sampling.png?raw=true)\n",
        "\n",
        "$p=0.92$とすると、*Top-p*サンプリングでは、$V_{\\text{top-p}}$と定義されている確率の$p=92\\%$を超える単語の*最小*数を選びます。最初の例では、最も可能性の高い9つの単語が含まれていましたが、2番目の例では、92％を超えるためには、上位3つの単語を選ぶだけです。とてもシンプルです。これは、次の単語が予測しにくい単語の広い範囲を保持していることがわかります*e.g.* $P(w | {\\text{\"The\"}})$と、次の単語が予測しやすいと思われるいくつかの単語だけを保持していることがわかります*e.g.* $P(w | {\\text{\"The\", \"car\"}})$.\n",
        "\n",
        "\n",
        "`0 < top_p < 1`を設定して、*Top-p*サンプリングを有効にします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvwIc7YAx77F",
        "outputId": "de1930b5-cf7b-455e-ebe7-9bd1dbf03f4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            "これから、楽しみにしていきたいと思います。\n",
            " 観光で訪れたことがない人も意外と多いと思うので、この記事では福岡の観光施設や駅周辺、駐車場の場所について紹介していきたいと思います。\n",
            "福岡の名所の一つである観光地の一つである天神を周り、一日で効率よく周ることができますので、福岡の代表的な観光スポットの一つとして定着している方もいると思います。\n",
            " また、地元の皆さんはちょっと足をのばすだけでもお店やお店がありますが、どんなお店が入っているのでしょうか。\n",
            "こちらの記事で、現在あるお店を紹介していきたいと思います。\n",
            "観光スポットの一つの、天神の立ち食いそば「オムそば」をご紹介します。\n",
            " 「オムそば」とは、奥行きのある赤いうどんやわらび、鍋の具材などから、見た目は地うどんのようですが、味はあっさりしていて、芋の風味と透明感のあるトリュフのような風味があります。\n",
            " 駅から歩いても近く、天神に観光に訪れた人も、一人でも気軽に立ち寄れるので、人気があります。\n",
            " というのも、初めては電車に乗ることが多いと思いますが、jr駅周辺など電車でのアクセスはとても便利で、福岡を観光したのに駅から直接駅まで行って食事ができる\n"
          ]
        }
      ],
      "source": [
        "# 結果の再現性担保のための設定。値を変えてみると、結果が変わります。\n",
        "set_seed(4)\n",
        "\n",
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    do_sample=True,  # サンプリングを有効化\n",
        "    top_p=0.92,  # 92%の確率の単語のみからサンプリングする。\n",
        "    top_k=0,  # top_kサンプリングを無効化\n",
        ")\n",
        "sample_output = model.generate(inputs, generation_config=config)\n",
        "\n",
        "generated = tokenizer.decode(sample_output[0], skip_special_tokens=True)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "# 見やすさのために、改行コードを挿入\n",
        "print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tn-8gLaR4lat"
      },
      "source": [
        "いい感じですね、人間が書いた感じがします。まあでもまだまだですね。\n",
        "\n",
        "理論的には *Top-p* の方が *Top-K* よりもエレガントに見えますが、実際にはどちらの方法もうまく機能します。*Top-p*は*Top-K*と組み合わせて使用することもでき、動的な選択を可能にしながら、非常に低いランクの単語を避けることができます。\n",
        "\n",
        "最後に、独立してサンプリングされた複数の出力を得るために、パラメータ `num_return_sequences > 1` を設定することができます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kY8P9VG8Gi9",
        "outputId": "97ded30f-bfb6-4d78-8731-1c5645dbd826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "0番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            " 九州と聞くと博多のイメージが浮かびますが、福岡も博多もそれぞれに魅力があります。\n",
            "なぜなら、福岡は九州の真ん中から近くて、福岡の市街地は九州の中でもかなり都会です。\n",
            "福岡は、九州の中では比較的温暖な土地にあります。\n",
            "気温が10度以下になると風が吹いていて、暑すぎるということもありません。\n",
            "また、福岡は冬も冬も寒暖の差が激しいので、過ごしやすいです。\n",
            "観光としてはあまり魅力がありませんが、自然を満喫したいという方は、自然体験をおすすめします。\n",
            " 福岡の定番土産といえば、博多味噌が有名です。\n",
            "博多は博多港に面していて、博多味噌は博多から海産物を買うこともできます。\n",
            "博多味噌は海産物として有名な博多味噌が有名です。\n",
            "福岡が一番好きな場所という方も多いですよね。\n",
            " 福岡土産として人気があるのは、福岡の美味しいものがたくさん販売されているお店や土産店です。\n",
            "福岡県の福岡は、美味しい食べ物やおいしいものがいっぱいありますので、お土産探しを楽しんでみてはいかがでしょうか。\n",
            "福岡には、たくさんの観光スポットがあります。\n",
            " 福岡といえば、やっぱりおしゃれで流行も\n",
            "\n",
            "1番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            " 福岡旅行は、福岡空港の博多口から船で博多港に直行し、博多へと向かいます。\n",
            "空港から船で福岡へと向かい、そこからフェリーで博多駅まで移動します。\n",
            "フェリーに乗るための運賃は2日間分となりますが、当日の出発や便数は変わります。\n",
            " 福岡には、国内有数の観光スポットがたくさんありますが、その中でも、特に人気の観光スポットの1つが福岡城です。\n",
            " 福岡城といえば、日本三大城のひとつで、有名な観光スポットの一つです。\n",
            "この記事では、福岡城の観光スポットや歴史をご紹介します。\n",
            " 九州旅行の定番の観光地である、九州五城のひとつ、博多城ですが、実は、福岡城内に本丸御殿があり、その外観は、なんと、国の重要文化財にも指定されているんです。\n",
            " 福岡城の天守閣といえば、国宝「九重御厨子」。\n",
            "九重御厨子の内部はとても見応えがあります。\n",
            "今回は、九重御厨子の内部をご紹介します。\n",
            " 福岡城は、安土桃山時代の1603年に築城された、国の重要伝統的建造物群保存地区です。\n",
            "現在は、天守閣と二の丸殿の二棟に、本丸御殿と二の丸殿があります。\n",
            "\n",
            "\n",
            "2番の生成結果\n",
            "福岡のご飯が美味しいと評判ですが、実際に観光地としてどういった魅力があるでしょうか。\n",
            "どんな観光体験が福岡に必要でしょうか。\n",
            "福岡で観光地として期待できることをまとめました。\n",
            " 太宰府天満宮や太宰府天満宮、そして福岡県の太宰府天満宮は多くの観光客が訪れる観光スポットです。\n",
            "福岡で魅力的な観光がしたいと考えたら、このエリアを拠点としてみてはいかがでしょうか。\n",
            " 太宰府天満宮は太宰府にあるおすすめの観光スポットです。\n",
            "太宰府天満宮をはじめ、太宰府周辺にあるお店をご紹介します。\n",
            " 太宰府天満宮には、大きな歴史があります。\n",
            "太宰府に縁のある人には、学問、武運、安産などを祈願する参拝スポットとしておすすめの場所です。\n",
            "太宰府には、学問の神様を祀る菅原道真公の墓所がある神社もあります。\n",
            " 太宰府にある天満宮は、学問の神様を祀る神様と、学問の神様を祀る菅原道真公の墓所があります。\n",
            "学問の神様は菅原道真公を祀る神社に祀られており、学問をすれば必ず勝るとされている有名な天満宮です。\n",
            " 太宰府天満宮は、福岡市にある神社である天満宮の近くにある神社です。\n",
            "学問の神様を祀る天満宮は、学問の神様を祀る天満宮が最も多いと言えるでしょう。\n",
            "学問の神様を祀る天満宮では、学問の成果が上がるよう、吉凶や運気などに関する祈願をすることができます\n"
          ]
        }
      ],
      "source": [
        "# 結果の再現性担保のための設定。値を変えてみてると、結果が変わります。\n",
        "set_seed(5)\n",
        "\n",
        "# テキスト生成用のconfigクラス\n",
        "config = GenerationConfig(\n",
        "    max_new_tokens=250,  # 出力の長さが250になるまで生成を続ける\n",
        "    do_sample=True,  # サンプリングを有効化\n",
        "    top_p=0.95,  # 95%の確率の単語のみからサンプリングする。\n",
        "    top_k=50,  # top_kとtop_pは同時に使える\n",
        "    num_return_sequences=3  # 候補を３つ返す\n",
        ")\n",
        "sample_outputs = model.generate(inputs, generation_config=config)\n",
        "\n",
        "# warinigが出ると見にくいので、出力の開始位置を表示\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  generated = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "\n",
        "  print(f\"\\n{i}番の生成結果\")\n",
        "  # 見やすさのために、改行コードを挿入\n",
        "  print(\"。\\n\".join(generated.split(\"。\")))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w4CYi91h11yd"
      },
      "source": [
        "### **その他のパラメタ**\n",
        "`generate` メソッドには、上では触れられていない追加のパラメータがいくつかあります。ここでは簡単に説明します\n",
        "\n",
        "- `min_length`は、`min_length`に到達する前にモデルがEOSトークンを生成しないように強制するために使われます。これは要約の際によく使われて、ユーザがより長い出力をしたい場合には一般的に便利です。\n",
        "- `repetition_penalty` は、既に生成された単語や文脈に属する単語にペナルティを与えるために用いることができます。繰り返しの防止にはかなり効果的ですが、異なるモデルやユースケースには非常に敏感に反応するようです。\n",
        "\n",
        "- `attention_mask` は、パディングされたトークンをマスクするために使うことができます。\n",
        "- `pad_token_id`, `bos_token_id`, `eos_token_id`. モデルがこれらのトークンをデフォルトで持っていない場合は、ユーザーが手動で他のトークンIDを選択して表現することができます。\n",
        "\n",
        "詳細は `generate` 関数 [docstring](https://huggingface.co/transformers/main_classes/model.html?highlight=generate#transformers.TFPreTrainedModel.generate) を参照してください。"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "82e52f2285c871893785b6211b1b0fb91a1e90d57630bc3da094798a3ae6fb15"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
